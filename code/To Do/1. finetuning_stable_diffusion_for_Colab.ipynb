{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Base Code : [How to Use DreamBooth to Fine-Tune Stable Diffusion (Colab)](https://bytexd.com/how-to-use-dreambooth-to-fine-tune-stable-diffusion-colab/)"
      ],
      "metadata": {
        "id": "pHrUCVMW12ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the enviroment"
      ],
      "metadata": {
        "id": "RiDUuCv81NC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jgDZFPvgLsQ",
        "outputId": "763618d8-3344-46c5-d5f8-226c5c2fec0a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "pbIRF0NIgH0D",
        "outputId": "0b597d2a-1c1e-471d-dc53-bf48b3a43c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "Upload requirements.txt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-61a684ba-745f-4b20-bafa-d9dffa115370\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-61a684ba-745f-4b20-bafa-d9dffa115370\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving requirements.txt to requirements.txt\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.9/524.9 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.0/144.0 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Done, proceed\n"
          ]
        }
      ],
      "source": [
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "import time\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "print('Installing dependencies...')\n",
        "print('Upload requirements.txt...')\n",
        "uploaded = files.upload()\n",
        "!pip install -r requirements.txt -q\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/\n",
        "    for i in range(1,6):\n",
        "        !wget -q \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies.{i}\"\n",
        "        !mv \"Dependencies.{i}\" \"Dependencies.7z.00{i}\"\n",
        "    !7z x -y Dependencies.7z.001\n",
        "    time.sleep(2)\n",
        "    %cd /content/usr/local/lib/python3.8/dist-packages\n",
        "    !rm -r PIL Pillow.libs Pillow-9.3.0.dist-info\n",
        "    !cp -r /content/usr/local/lib/python3.8/dist-packages /usr/local/lib/python3.8/\n",
        "    !rm -r /content/usr\n",
        "    %cd /content\n",
        "    for i in range(1,6):\n",
        "        !rm \"Dependencies.7z.00{i}\"\n",
        "    !pip uninstall -y diffusers\n",
        "    !git clone --branch updt https://github.com/TheLastBen/diffusers\n",
        "    !pip install -q /content/diffusers\n",
        "    s = getoutput('nvidia-smi')\n",
        "    if \"A100\" in s:\n",
        "        !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/A100\n",
        "        !rm -r /usr/local/lib/python3.8/dist-packages/xformers\n",
        "        %cd /usr/local/lib/python3.8/dist-packages/\n",
        "        !7z x -y /content/A100\n",
        "        !rm /content/A100\n",
        "        %cd /content/\n",
        "print('Done, proceed')\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "import shutil\n",
        "from os import listdir\n",
        "from os.path import isfile\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def downloadmodel():\n",
        "    token=Huggingface_Token\n",
        "    # if token==\"\":\n",
        "    #     token=input(\"Insert your huggingface token :\")\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "        !rm -r /content/stable-diffusion-v1-5\n",
        "    clear_output()\n",
        "\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    !mkdir /content/stable-diffusion-v1-5\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "        !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "        !rm -r /content/stable-diffusion-v1-5/.git\n",
        "        %cd /content/stable-diffusion-v1-5\n",
        "        !rm model_index.json\n",
        "        time.sleep(1)    \n",
        "        wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "        !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "        !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "        !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json  \n",
        "        %cd /content/    \n",
        "        clear_output()\n",
        "        print('DONE !')\n",
        "    else:\n",
        "        while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "            print('Make sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "            time.sleep(5)"
      ],
      "metadata": {
        "id": "ejhjMOzogQWz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_session():\n",
        "    if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
        "        print('Loading session with no previous model, using the original model or the custom downloaded model')\n",
        "        if MODEL_NAME==\"\":\n",
        "            print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "        else:\n",
        "            print('Session Loaded, proceed to uploading instance images')\n",
        "\n",
        "    elif os.path.exists(MDLPTH):\n",
        "        print('Session found, loading the trained model ...')\n",
        "        !wget -q -O refmdlz https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/refmdlz\n",
        "        !unzip -o -q refmdlz\n",
        "        !rm -f refmdlz\n",
        "        !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv1.py\n",
        "        clear_output()\n",
        "        print('Session found, loading the trained model ...')\n",
        "        !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v1\n",
        "        !rm -r /content/refmdl\n",
        "        !rm /content/convertodiff.py  \n",
        "        if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "            resume=True    \n",
        "            clear_output()\n",
        "            print('Session loaded.')\n",
        "        else:     \n",
        "            if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "                print('Conversion error, if the error persists, remove the CKPT file from the current session folder')\n",
        "\n",
        "    elif not os.path.exists(str(SESSION_DIR)):\n",
        "        %mkdir -p \"$INSTANCE_DIR\"\n",
        "        print('Creating session...')\n",
        "        if MODEL_NAME==\"\":\n",
        "            print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "        else:\n",
        "            print('Session created, proceed to uploading instance images')\n",
        "\n",
        "def prepare_image_upload():\n",
        "    if os.path.exists(CAPTIONS_DIR+\"off\"):\n",
        "        !mv $CAPTIONS_DIR\"off\" $CAPTIONS_DIR\n",
        "        time.sleep(3)\n",
        "\n",
        "    if os.path.exists(str(INSTANCE_DIR)):\n",
        "        !rm -r \"$INSTANCE_DIR\"\n",
        "    if os.path.exists(str(CAPTIONS_DIR)):\n",
        "        !rm -r \"$CAPTIONS_DIR\"\n",
        "\n",
        "    if not os.path.exists(str(INSTANCE_DIR)):\n",
        "        %mkdir -p \"$INSTANCE_DIR\"\n",
        "    if not os.path.exists(str(CAPTIONS_DIR)):\n",
        "        %mkdir -p \"$CAPTIONS_DIR\"\n",
        "\n",
        "    if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "        %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "def uploaded_image():\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.split(\".\")[-1]==\"txt\":\n",
        "            shutil.move(filename, CAPTIONS_DIR)\n",
        "        up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n",
        "        \n",
        "\n",
        "\n",
        "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "        shutil.move(filename, INSTANCE_DIR)\n",
        "        clear_output()\n",
        "    print('upload image 분리 Done, proceed to the next cell')\n",
        "\n",
        "    with capture.capture_output() as cap:\n",
        "        %cd \"$INSTANCE_DIR\"\n",
        "        !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "        %cd \"$CAPTIONS_DIR\"\n",
        "        !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "        \n",
        "        %cd $SESSION_DIR\n",
        "        !rm instance_images.zip captions.zip\n",
        "        !zip -r instance_images instance_images\n",
        "        !zip -r captions captions\n",
        "        %cd /content\n",
        "\n",
        "\n",
        "def prepare_training():\n",
        "    if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "        %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "    if os.path.exists(CONCEPT_DIR+\"/.ipynb_checkpoints\"):\n",
        "        %rm -r $CONCEPT_DIR\"/.ipynb_checkpoints\"  \n",
        "\n",
        "    if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n",
        "        %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"    \n",
        "\n",
        "    if os.path.exists(CAPTIONS_DIR+\"off\"):\n",
        "        !mv $CAPTIONS_DIR\"off\" $CAPTIONS_DIR\n"
      ],
      "metadata": {
        "id": "iPbpS3vfgRd7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Huggingface_Token = \"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\"\n",
        "token=Huggingface_Token\n",
        "\n",
        "# Session Name\n",
        "print('Input the Session Name:') \n",
        "Session_Name=input('')\n",
        "\n",
        "# 디렉토리 선언\n",
        "WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n",
        "INSTANCE_NAME=Session_Name\n",
        "OUTPUT_DIR=\"/content/models/\"+ Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+ Session_Name\n",
        "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
        "CONCEPT_DIR=SESSION_DIR+'/concept_images'\n",
        "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
        "MDLPTH=str(SESSION_DIR+\"/\"+ Session_Name+'.ckpt')\n",
        "PT=\"\"\n",
        "\n",
        "# Model Download\n",
        "if not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    downloadmodel()\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "else:\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "    print(\"The v1.5 model already exists, using this model.\")  \n",
        "    \n",
        "# create/load session\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content\n",
        "create_session()\n",
        "\n",
        "# Instant_image\n",
        "prepare_image_upload()\n",
        "\n",
        "up=\"\"  \n",
        "uploaded = files.upload()\n",
        "\n",
        "uploaded_image()\n",
        "with capture.capture_output() as cap:\n",
        "    %cd \"$INSTANCE_DIR\"\n",
        "    !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "    %cd \"$CAPTIONS_DIR\"\n",
        "    !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "    \n",
        "    %cd $SESSION_DIR\n",
        "    !rm instance_images.zip captions.zip\n",
        "    !zip -r instance_images instance_images\n",
        "    !zip -r captions captions\n",
        "    %cd /content\n",
        "    \n",
        "# traing\n",
        "prepare_training()"
      ],
      "metadata": {
        "id": "2scWKIO9giMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Part (Not complete)"
      ],
      "metadata": {
        "id": "z9dDPXQZ1JCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Resume_Training = False\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "\n",
        "# UNET\n",
        "UNet_Training_Steps=100 #650 \n",
        "untlr = 1e-5 # UNet_Learning_Rate\n",
        "\n",
        "trnonltxt=\"\"    \n",
        "\n",
        "# TextEncoder\n",
        "Text_Encoder_Training_Steps=100 #250 \n",
        "Text_Encoder_Concept_Training_Steps=0 \n",
        "txlr = 1e-6 # Text_Encoder_Learning_Rate\n",
        "\n",
        "Enable_text_encoder_training= True \n",
        "Enable_Text_Encoder_Concept_Training= True\n",
        "\n",
        "stptxt=Text_Encoder_Training_Steps\n",
        "\n",
        "Enable_Text_Encoder_Concept_Training= False\n",
        "Textenc=\"--train_text_encoder\"\n",
        "    \n",
        "# External_Captions\n",
        "extrnlcptn=\"\"\n",
        "\n",
        "# Style\n",
        "Style=\"\"\n",
        "\n",
        "# Resolution\n",
        "Resolution = \"512\" \n",
        "Res=int(Resolution)\n",
        "\n",
        "# seed\n",
        "Seed=random.randint(1, 999999)  \n",
        "\n",
        "# GC\n",
        "GC=\"--gradient_checkpointing\"\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "    GC=\"\"\n",
        "    \n",
        "fp16 = True\n",
        "prec=\"fp16\"\n",
        "precision=prec\n",
        "\n",
        "\n",
        "# resuming\n",
        "resuming=\"\"\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    MODELT_NAME=OUTPUT_DIR\n",
        "    print('[1;32mResuming Training...[0m')\n",
        "    resuming=\"Yes\"\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    print('[1;31mPrevious model not found, training a new model...[0m')\n",
        "    MODELT_NAME=MODEL_NAME\n",
        "    while MODEL_NAME==\"\":\n",
        "        print('[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "        time.sleep(5)\n",
        "\n",
        "V2=False\n",
        "\n",
        "Save_Checkpoint_Every=500 \n",
        "stp=0\n",
        "Start_saving_from_the_step=500 \n",
        "stpsv=Start_saving_from_the_step\n",
        "\n",
        "Disconnect_after_training=False \n",
        "\n",
        "\n",
        "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "    \n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $trnonltxt \\\n",
        "    --image_captions_filename \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$txlr \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
        "    clear_output()\n",
        "    if resuming==\"Yes\":\n",
        "        print('[1;32mResuming Training...[0m')    \n",
        "    print('[1;33mTraining the UNet...[0m')\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Style \\\n",
        "    $extrnlcptn \\\n",
        "    --stop_text_encoder_training=$Text_Encoder_Training_Steps \\\n",
        "    --image_captions_filename \\\n",
        "    --train_only_unet \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$untlr \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "\n",
        "if Enable_text_encoder_training :\n",
        "    print('[1;33mTraining the text encoder...[0m')\n",
        "    if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
        "        %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
        "    dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "\n",
        "if Enable_Text_Encoder_Concept_Training:\n",
        "    if os.path.exists(CONCEPT_DIR):\n",
        "        if os.listdir(CONCEPT_DIR)!=[]:\n",
        "            clear_output()\n",
        "            if resuming==\"Yes\":\n",
        "                print('[1;32mResuming Training...[0m')\n",
        "                print('[1;33mTraining the text encoder on the concept...[0m')\n",
        "                dump_only_textenc(trnonltxt, MODELT_NAME, CONCEPT_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxtc)\n",
        "        else:\n",
        "            clear_output()\n",
        "            if resuming==\"Yes\":\n",
        "                print('[1;32mResuming Training...[0m')      \n",
        "            print('[1;31mNo concept images found, skipping concept training...')\n",
        "            time.sleep(8)\n",
        "    else:\n",
        "        clear_output()\n",
        "        if resuming==\"Yes\":\n",
        "            print('[1;32mResuming Training...[0m')\n",
        "        print('[1;31mNo concept images found, skipping concept training...')\n",
        "        time.sleep(8)\n",
        "      \n",
        "if UNet_Training_Steps!=0:\n",
        "    train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n",
        "    \n",
        "\n",
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n",
        "    if V2:\n",
        "        !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n",
        "        clear_output()\n",
        "        if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "            clear_output()\n",
        "            print(\"[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n",
        "            if Disconnect_after_training :\n",
        "                time.sleep(20)\n",
        "                runtime.unassign()\n",
        "        else:\n",
        "            print(\"[1;31mSomething went wrong\")\n",
        "    else:  \n",
        "        !wget -q -O /content/convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "        if precision==\"no\":\n",
        "            !sed -i '226s@.*@@' /content/convertosd.py\n",
        "        !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "        !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
        "        !python /content/convertosd.py\n",
        "        !rm /content/convertosd.py\n",
        "        clear_output()\n",
        "        if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "            print(\"[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n",
        "            if Disconnect_after_training :\n",
        "                time.sleep(20)\n",
        "                runtime.unassign()\n",
        "        else:\n",
        "            print(\"[1;31mSomething went wrong\")\n",
        "    \n",
        "else:\n",
        "    print(\"[1;31mSomething went wrong\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtNkJ4gkmJfc",
        "outputId": "a0c0e5a0-6319-449e-aac6-bd7e2508eedd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\n"
          ]
        }
      ]
    }
  ]
}