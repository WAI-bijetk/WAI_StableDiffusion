{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHrUCVMW12ig"
      },
      "source": [
        "Base Code : [How to Use DreamBooth to Fine-Tune Stable Diffusion (Colab)](https://bytexd.com/how-to-use-dreambooth-to-fine-tune-stable-diffusion-colab/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiDUuCv81NC9"
      },
      "source": [
        "## Setting up the enviroment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jgDZFPvgLsQ",
        "outputId": "4e8b0812-b8aa-42cf-9534-0c46fd6ed919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbIRF0NIgH0D",
        "outputId": "a60c630a-482c-4ae4-c120-d5f8b90f965f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mInstalling dependencies...\n",
            "\u001b[1;32mDone, proceed\n"
          ]
        }
      ],
      "source": [
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "import time\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "print('\u001b[1;32mInstalling dependencies...')\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/\n",
        "    !pip install -q --no-deps accelerate==0.12.0\n",
        "    !wget -q -i \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/dbdeps.txt\"\n",
        "    for i in range(1,8):\n",
        "        !mv \"deps.{i}\" \"deps.7z.00{i}\"\n",
        "    !7z x -y -o/ deps.7z.001\n",
        "    !rm *.00* *.txt\n",
        "    !git clone --depth 1 --branch updt https://github.com/TheLastBen/diffusers\n",
        "    s = getoutput('nvidia-smi')\n",
        "    if \"A100\" in s:\n",
        "        !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/A100\n",
        "        !rm -r /usr/local/lib/python3.8/dist-packages/xformers\n",
        "        !7z x -y -o/usr/local/lib/python3.8/dist-packages/ /content/A100\n",
        "        !rm /content/A100\n",
        "print('\u001b[1;32mDone, proceed')\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "import shutil\n",
        "from os import listdir\n",
        "from os.path import isfile\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "import random\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ejhjMOzogQWz"
      },
      "outputs": [],
      "source": [
        "def downloadmodel(token):\n",
        "    token=token\n",
        "    # if token==\"\":\n",
        "    #     token=input(\"Insert your huggingface token :\")\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "        !rm -r /content/stable-diffusion-v1-5\n",
        "    clear_output()\n",
        "\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    !mkdir /content/stable-diffusion-v1-5\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nfeature_extractor\\nsafety_checker\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "        !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "        !rm -r /content/stable-diffusion-v1-5/.git\n",
        "        %cd /content/stable-diffusion-v1-5\n",
        "        !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "        !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "        !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json  \n",
        "        %cd /content/    \n",
        "        clear_output()\n",
        "        print('DONE !')\n",
        "    else:\n",
        "        while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "            print('Make sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "            time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iPbpS3vfgRd7"
      },
      "outputs": [],
      "source": [
        "def sd_custom_create_session():\n",
        "    if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
        "        print('Loading session with no previous model, using the original model or the custom downloaded model')\n",
        "        if MODEL_NAME==\"\":\n",
        "            print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "        else:\n",
        "            print('Session Loaded, proceed to uploading instance images')\n",
        "\n",
        "    elif os.path.exists(MDLPTH):\n",
        "        print('Session found, loading the trained model ...')\n",
        "        !wget -q -O refmdlz https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/refmdlz\n",
        "        !unzip -o -q refmdlz\n",
        "        !rm -f refmdlz\n",
        "        !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv1.py\n",
        "        clear_output()\n",
        "        print('Session found, loading the trained model ...')\n",
        "        !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v1\n",
        "        !rm -r /content/refmdl\n",
        "        !rm /content/convertodiff.py  \n",
        "        if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "            resume=True    \n",
        "            clear_output()\n",
        "            print('Session loaded.')\n",
        "        else:     \n",
        "            if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "                print('Conversion error, if the error persists, remove the CKPT file from the current session folder')\n",
        "\n",
        "    elif not os.path.exists(str(SESSION_DIR)):\n",
        "        %mkdir -p \"$INSTANCE_DIR\"\n",
        "        print('Creating session...')\n",
        "        if MODEL_NAME==\"\":\n",
        "            print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "        else:\n",
        "            print('Session created, proceed to uploading instance images')\n",
        "\n",
        "def sd_custom_prepare_image_upload():\n",
        "    if os.path.exists(CAPTIONS_DIR+\"off\"):\n",
        "        !mv $CAPTIONS_DIR\"off\" $CAPTIONS_DIR\n",
        "        time.sleep(3)\n",
        "\n",
        "    if os.path.exists(str(INSTANCE_DIR)):\n",
        "        !rm -r \"$INSTANCE_DIR\"\n",
        "    if os.path.exists(str(CAPTIONS_DIR)):\n",
        "        !rm -r \"$CAPTIONS_DIR\"\n",
        "\n",
        "    if not os.path.exists(str(INSTANCE_DIR)):\n",
        "        %mkdir -p \"$INSTANCE_DIR\"\n",
        "    if not os.path.exists(str(CAPTIONS_DIR)):\n",
        "        %mkdir -p \"$CAPTIONS_DIR\"\n",
        "\n",
        "    if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "        %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "def sd_custom_uploaded_image():\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.split(\".\")[-1]==\"txt\":\n",
        "            shutil.move(filename, CAPTIONS_DIR)\n",
        "        up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n",
        "        \n",
        "\n",
        "\n",
        "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "        shutil.move(filename, INSTANCE_DIR)\n",
        "        clear_output()\n",
        "    print('upload image 분리 Done, proceed to the next cell')\n",
        "\n",
        "    with capture.capture_output() as cap:\n",
        "        %cd \"$INSTANCE_DIR\"\n",
        "        !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "        %cd \"$CAPTIONS_DIR\"\n",
        "        !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "        \n",
        "        %cd $SESSION_DIR\n",
        "        !rm instance_images.zip captions.zip\n",
        "        !zip -r instance_images instance_images\n",
        "        !zip -r captions captions\n",
        "        %cd /content\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "    \n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $trnonltxt \\\n",
        "    --image_captions_filename \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$txlr \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "def train_only_unet(stptxt, stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
        "    clear_output()\n",
        "    print('Training the UNet...')\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Style \\\n",
        "    $extrnlcptn \\\n",
        "    --stop_text_encoder_training=$stptxt \\\n",
        "    --image_captions_filename \\\n",
        "    --train_only_unet \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$untlr \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "def sd_custom_training():\n",
        "    import os\n",
        "    from subprocess import getoutput\n",
        "    from IPython.display import clear_output\n",
        "    from google.colab import runtime\n",
        "    import time\n",
        "    import random\n",
        "\n",
        "    Resume_Training = False\n",
        "\n",
        "    # if resume and not Resume_Training:\n",
        "    #   print('[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?')\n",
        "    #   while True:\n",
        "    #     ansres=input('')\n",
        "    #     if ansres=='no':\n",
        "    #       Resume_Training = True\n",
        "    #       break\n",
        "    #     elif ansres=='yes':\n",
        "    #       Resume_Training = False\n",
        "    #       resume= False\n",
        "    #       break\n",
        "\n",
        "    # while not Resume_Training and MODEL_NAME==\"\":\n",
        "    #   print('[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "    #   time.sleep(5)\n",
        "\n",
        "    MODELT_NAME=MODEL_NAME\n",
        "\n",
        "    # UNet\n",
        "    UNet_Training_Steps=800 \n",
        "    UNet_Learning_Rate = 1e-5\n",
        "    untlr=UNet_Learning_Rate\n",
        "\n",
        "    # Text_Encoder\n",
        "    Enable_text_encoder_training= True\n",
        "    Text_Encoder_Training_Steps=350\n",
        "    Text_Encoder_Learning_Rate = 1e-6 #param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n",
        "    stptxt=Text_Encoder_Training_Steps\n",
        "    txlr=Text_Encoder_Learning_Rate\n",
        "\n",
        "    Enable_Text_Encoder_Concept_Training= False\n",
        "    Text_Encoder_Concept_Training_Steps=0\n",
        "\n",
        "    # Seed\n",
        "    Seed=\"\"\n",
        "    if Seed =='' or Seed=='0':\n",
        "      Seed=random.randint(1, 999999)\n",
        "    else:\n",
        "      Seed=int(Seed)\n",
        "    print(type(Seed))\n",
        "    trnonltxt=\"\"\n",
        "\n",
        "    extrnlcptn=\"\"\n",
        "    Style=\"\"\n",
        "\n",
        "    Resolution = \"512\" #param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "    Res=int(Resolution)\n",
        "\n",
        "    fp16 = True\n",
        "    prec=\"fp16\"\n",
        "    precision=prec\n",
        "\n",
        "    GC=\"--gradient_checkpointing\"\n",
        "    s = getoutput('nvidia-smi')\n",
        "    if 'A100' in s:\n",
        "      GC=\"\"\n",
        "      \n",
        "    External_Captions = False\n",
        "\n",
        "    resuming=\"\"\n",
        "\n",
        "    stp=0\n",
        "    Start_saving_from_the_step=0\n",
        "    stpsv=Start_saving_from_the_step\n",
        "\n",
        "    Disconnect_after_training=False\n",
        "\n",
        "    \n",
        "    # 텍스트 인코더 트레이닝\n",
        "    if Enable_text_encoder_training :\n",
        "      print('Training the text encoder...')\n",
        "      if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
        "        %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
        "      dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "\n",
        "    # 유넷 트레이닝\n",
        "    if UNet_Training_Steps!=0:\n",
        "      train_only_unet(Text_Encoder_Training_Steps, stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n",
        "\n",
        "    # if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "    #     prc=\"--fp16\" if precision==\"fp16\" else \"\"\n",
        "    #     !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n",
        "    #     clear_output()\n",
        "    #     if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "    #         clear_output()\n",
        "    #         print(\"DONE, the CKPT model is in your Gdrive in the sessions folder\")\n",
        "\n",
        "    #     else:\n",
        "    #         print(\"[1;31mSomething went wrong\")\n",
        "    # else:\n",
        "    #     print(\"[1;31mSomething went wrong\")    \n",
        "\n",
        "\n",
        "    shutil.copytree(\"/content/stable-diffusion-v1-5/feature_extractor\", OUTPUT_DIR + \"/feature_extractor\")\n",
        "    shutil.copytree(\"/content/stable-diffusion-v1-5/safety_checker\", OUTPUT_DIR + \"/safety_checker\")\n",
        "    shutil.copyfile('/content/stable-diffusion-v1-5/model_index.json', OUTPUT_DIR + \"/model_index.json\")"
      ],
      "metadata": {
        "id": "PgoWcKT2GjkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2scWKIO9giMb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "outputId": "15e7567a-5cd1-4784-fe70-b1e3a632bb15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  |███████████████| 21/21 Uploaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "upload image 분리 Done, proceed to the next cell\n"
          ]
        }
      ],
      "source": [
        "Huggingface_Token = \"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\"\n",
        "token=Huggingface_Token\n",
        "\n",
        "# Session Name\n",
        "print('Input the Session Name:') \n",
        "Session_Name=input('')\n",
        "\n",
        "# 디렉토리 선언\n",
        "WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n",
        "INSTANCE_NAME=Session_Name\n",
        "OUTPUT_DIR=\"/content/models/\"+ Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+ Session_Name\n",
        "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
        "CONCEPT_DIR=SESSION_DIR+'/concept_images'\n",
        "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
        "MDLPTH=str(SESSION_DIR+\"/\"+ Session_Name+'.ckpt')\n",
        "PT=\"\"\n",
        "\n",
        "# Model Download\n",
        "if not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    downloadmodel(token)\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "else:\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "    print(\"The v1.5 model already exists, using this model.\")  \n",
        "    \n",
        "# create/load session\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content\n",
        "sd_custom_create_session()\n",
        "\n",
        "# Instant_image\n",
        "# sd_custom_prepare_image_upload()\n",
        "\n",
        "up=\"\"  \n",
        "uploaded = files.upload()\n",
        "\n",
        "sd_custom_uploaded_image()\n",
        "with capture.capture_output() as cap:\n",
        "    %cd \"$INSTANCE_DIR\"\n",
        "    !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "    %cd \"$CAPTIONS_DIR\"\n",
        "    !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "    \n",
        "    %cd $SESSION_DIR\n",
        "    !rm instance_images.zip captions.zip\n",
        "    !zip -r instance_images instance_images\n",
        "    !zip -r captions captions\n",
        "    %cd /content\n",
        "    \n",
        "# training\n",
        "sd_custom_training()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9dDPXQZ1JCb"
      },
      "source": [
        "## Training Part (Not complete)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sd_custom_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "oZXHj4AA-fxA",
        "outputId": "6d07038e-a9ad-4c53-e078-03065b628795"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the UNet...\n",
            "\u001b[34m'########:'########:::::'###::::'####:'##::: ##:'####:'##::: ##::'######:::\n",
            "... ##..:: ##.... ##:::'## ##:::. ##:: ###:: ##:. ##:: ###:: ##:'##... ##::\n",
            "::: ##:::: ##:::: ##::'##:. ##::: ##:: ####: ##:: ##:: ####: ##: ##:::..:::\n",
            "::: ##:::: ########::'##:::. ##:: ##:: ## ## ##:: ##:: ## ## ##: ##::'####:\n",
            "::: ##:::: ##.. ##::: #########:: ##:: ##. ####:: ##:: ##. ####: ##::: ##::\n",
            "::: ##:::: ##::. ##:: ##.... ##:: ##:: ##:. ###:: ##:: ##:. ###: ##::: ##::\n",
            "::: ##:::: ##:::. ##: ##:::: ##:'####: ##::. ##:'####: ##::. ##:. ######:::\n",
            ":::..:::::..:::::..::..:::::..::....::..::::..::....::..::::..:::......::::\n",
            "\u001b[0m\n",
            "Progress:|█████████████████████████|100% 800/800 [11:30<00:00,  1.16it/s, loss=0.0504, lr=1e-7]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-dfcee049835b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msd_custom_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-3a4389c2f6c2>\u001b[0m in \u001b[0;36msd_custom_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/stable-diffusion-v1-5/feature_extractor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/feature_extractor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/stable-diffusion-v1-5/safety_checker\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/safety_checker\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/stable-diffusion-v1-5/model_index.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/model_index.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n\u001b[0m\u001b[1;32m    558\u001b[0m                      \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                      \u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36m_copytree\u001b[0;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mignored_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirs_exist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0muse_srcentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcopy2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcopy_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/models/test1708/feature_extractor'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}