{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHrUCVMW12ig"
      },
      "source": [
        "Base Code : [How to Use DreamBooth to Fine-Tune Stable Diffusion (Colab)](https://bytexd.com/how-to-use-dreambooth-to-fine-tune-stable-diffusion-colab/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiDUuCv81NC9"
      },
      "source": [
        "## Setting up the enviroment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jgDZFPvgLsQ",
        "outputId": "50871666-917f-492c-8d06-5365bf6591a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbIRF0NIgH0D",
        "outputId": "173fe8db-2cbb-4af9-8617-ca62cf6edbf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "Upload requirements.txt...\n",
            "Done, proceed\n"
          ]
        }
      ],
      "source": [
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "import time\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "print('Installing dependencies...')\n",
        "print('Upload requirements.txt...')\n",
        "# uploaded = files.upload()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/\n",
        "    # !pip install -r requirements.txt -q\n",
        "    !pip install -q --no-deps accelerate==0.12.0\n",
        "    !wget -q -i \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/dbdeps.txt\"\n",
        "    for i in range(1,8):\n",
        "        !mv \"deps.{i}\" \"deps.7z.00{i}\"\n",
        "    !7z x -y -o/ deps.7z.001\n",
        "    !rm *.00* *.txt\n",
        "    !git clone --depth 1 --branch updt https://github.com/TheLastBen/diffusers\n",
        "    s = getoutput('nvidia-smi')\n",
        "    if \"A100\" in s:\n",
        "        !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/A100\n",
        "        !rm -r /usr/local/lib/python3.8/dist-packages/xformers\n",
        "        !7z x -y -o/usr/local/lib/python3.8/dist-packages/ /content/A100\n",
        "        !rm /content/A100\n",
        "print('Done, proceed')\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "import shutil\n",
        "from os import listdir\n",
        "from os.path import isfile\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "import random\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Definition"
      ],
      "metadata": {
        "id": "6jjHEqIPsNd5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iPbpS3vfgRd7"
      },
      "outputs": [],
      "source": [
        "def downloadmodel(token):\n",
        "    token=token\n",
        "    \n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "        !rm -r /content/stable-diffusion-v1-5\n",
        "    clear_output()\n",
        "\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    !mkdir /content/stable-diffusion-v1-5\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nfeature_extractor\\nsafety_checker\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "        !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "        !rm -r /content/stable-diffusion-v1-5/.git\n",
        "        %cd /content/stable-diffusion-v1-5\n",
        "        !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "        !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "        !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json  \n",
        "        %cd /content/    \n",
        "        clear_output()\n",
        "        print('DONE !')\n",
        "    else:\n",
        "        while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "            print('Make sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "            time.sleep(5)\n",
        "\n",
        "def sd_custom_create_session(MODEL_NAME, SESSION_DIR, MDLPTH, OUTPUT_DIR):\n",
        "    if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
        "        print('Loading session with no previous model, using the original model or the custom downloaded model')\n",
        "        if MODEL_NAME==\"\":\n",
        "            print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "        else:\n",
        "            print('Session Loaded, proceed to uploading instance images')\n",
        "\n",
        "    elif os.path.exists(MDLPTH):\n",
        "        print('Session found, loading the trained model ...')\n",
        "        !wget -q -O refmdlz https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/refmdlz\n",
        "        !unzip -o -q refmdlz\n",
        "        !rm -f refmdlz\n",
        "        !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv1.py\n",
        "        clear_output()\n",
        "        print('Session found, loading the trained model ...')\n",
        "        !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v1\n",
        "        !rm -r /content/refmdl\n",
        "        !rm /content/convertodiff.py  \n",
        "        if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "            resume=True    \n",
        "            clear_output()\n",
        "            print('Session loaded.')\n",
        "        else:     \n",
        "            if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "                print('Conversion error, if the error persists, remove the CKPT file from the current session folder')\n",
        "\n",
        "    elif not os.path.exists(str(SESSION_DIR)):\n",
        "        %mkdir -p \"$INSTANCE_DIR\"\n",
        "        print('Creating session...')\n",
        "        if MODEL_NAME==\"\":\n",
        "            print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "        else:\n",
        "            print('Session created, proceed to uploading instance images')\n",
        "\n",
        "def sd_custom_prepare_image_upload(CAPTIONS_DIR, INSTANCE_DIR):\n",
        "    if os.path.exists(CAPTIONS_DIR+\"off\"):\n",
        "        !mv $CAPTIONS_DIR\"off\" $CAPTIONS_DIR\n",
        "        time.sleep(3)\n",
        "\n",
        "    if os.path.exists(str(INSTANCE_DIR)):\n",
        "        !rm -r \"$INSTANCE_DIR\"\n",
        "    if os.path.exists(str(CAPTIONS_DIR)):\n",
        "        !rm -r \"$CAPTIONS_DIR\"\n",
        "\n",
        "    if not os.path.exists(str(INSTANCE_DIR)):\n",
        "        %mkdir -p \"$INSTANCE_DIR\"\n",
        "    if not os.path.exists(str(CAPTIONS_DIR)):\n",
        "        %mkdir -p \"$CAPTIONS_DIR\"\n",
        "\n",
        "    if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "        %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "def sd_custom_uploaded_image(CAPTION_DIR, INSTANCE_DIR):\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.split(\".\")[-1]==\"txt\":\n",
        "            shutil.move(filename, CAPTIONS_DIR)\n",
        "        up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n",
        "        \n",
        "\n",
        "\n",
        "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "        shutil.move(filename, INSTANCE_DIR)\n",
        "        clear_output()\n",
        "    print('upload image 분리 Done, proceed to the next cell')\n",
        "\n",
        "    with capture.capture_output() as cap:\n",
        "        %cd \"$INSTANCE_DIR\"\n",
        "        !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "        %cd \"$CAPTIONS_DIR\"\n",
        "        !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "        \n",
        "        %cd $SESSION_DIR\n",
        "        !rm instance_images.zip captions.zip\n",
        "        !zip -r instance_images instance_images\n",
        "        !zip -r captions captions\n",
        "        %cd /content\n",
        "\n",
        "\n",
        "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "    \n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $trnonltxt \\\n",
        "    --image_captions_filename \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$txlr \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "def train_only_unet(stptxt, stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
        "    clear_output()\n",
        "    print('Training the UNet...')\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Style \\\n",
        "    $extrnlcptn \\\n",
        "    --stop_text_encoder_training=$stptxt \\\n",
        "    --image_captions_filename \\\n",
        "    --train_only_unet \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$untlr \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2scWKIO9giMb"
      },
      "outputs": [],
      "source": [
        "def sd_custom_function(token, Session_Name, UNet_Training_Steps, UNet_Learning_Rate, Text_Encoder_Training_Steps, Text_Encoder_Learning_Rate):\n",
        "    import os\n",
        "    from subprocess import getoutput\n",
        "    from IPython.display import clear_output\n",
        "    from google.colab import runtime\n",
        "    import time\n",
        "    import random\n",
        "    # 디렉토리 선언\n",
        "    WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n",
        "    INSTANCE_NAME=Session_Name\n",
        "    OUTPUT_DIR=\"/content/models/\"+ Session_Name\n",
        "    SESSION_DIR=WORKSPACE+'/Sessions/'+ Session_Name\n",
        "    INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
        "    CONCEPT_DIR=SESSION_DIR+'/concept_images'\n",
        "    CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
        "    MDLPTH=str(SESSION_DIR+\"/\"+ Session_Name+'.ckpt')\n",
        "    PT=\"\"\n",
        "\n",
        "    # Model Download\n",
        "    if not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "        downloadmodel(token)\n",
        "        MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "    else:\n",
        "        MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "        print(\"The v1.5 model already exists, using this model.\")  \n",
        "        \n",
        "    # create/load session\n",
        "    with capture.capture_output() as cap:\n",
        "        %cd /content\n",
        "    sd_custom_create_session(MODEL_NAME, SESSION_DIR, MDLPTH, OUTPUT_DIR)\n",
        "\n",
        "    # Instant_image\n",
        "    sd_custom_prepare_image_upload(CAPTIONS_DIR, INSTANCE_DIR)\n",
        "\n",
        "    up=\"\"  \n",
        "    uploaded = files.upload()\n",
        "\n",
        "    sd_custom_uploaded_image(CAPTIONS_DIR, INSTANCE_DIR)\n",
        "    with capture.capture_output() as cap:\n",
        "        %cd \"$INSTANCE_DIR\"\n",
        "        !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "        %cd \"$CAPTIONS_DIR\"\n",
        "        !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "        \n",
        "        %cd $SESSION_DIR\n",
        "        !rm instance_images.zip captions.zip\n",
        "        !zip -r instance_images instance_images\n",
        "        !zip -r captions captions\n",
        "        %cd /content\n",
        "        \n",
        "    # training\n",
        "    \n",
        "\n",
        "    Resume_Training = False\n",
        "\n",
        "    MODELT_NAME=MODEL_NAME\n",
        "    print(MODELT_NAME)\n",
        "    print(OUTPUT_DIR)\n",
        "    # UNet\n",
        "    UNet_Training_Steps=UNet_Training_Steps \n",
        "    UNet_Learning_Rate = UNet_Learning_Rate\n",
        "    untlr=UNet_Learning_Rate\n",
        "\n",
        "    # Text_Encoder\n",
        "    Enable_text_encoder_training= True\n",
        "    Text_Encoder_Training_Steps=Text_Encoder_Training_Steps\n",
        "    Text_Encoder_Learning_Rate = Text_Encoder_Learning_Rate #param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n",
        "    stptxt=Text_Encoder_Training_Steps\n",
        "    txlr=Text_Encoder_Learning_Rate\n",
        "\n",
        "    Enable_Text_Encoder_Concept_Training= False\n",
        "    Text_Encoder_Concept_Training_Steps=0\n",
        "\n",
        "    # Seed\n",
        "    Seed=\"\"\n",
        "    if Seed =='' or Seed=='0':\n",
        "        Seed=random.randint(1, 999999)\n",
        "    else:\n",
        "        Seed=int(Seed)\n",
        "    print(type(Seed))\n",
        "    trnonltxt=\"\"\n",
        "\n",
        "    extrnlcptn=\"\"\n",
        "    Style=\"\"\n",
        "\n",
        "    Resolution = \"512\" #param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "    Res=int(Resolution)\n",
        "\n",
        "    fp16 = True\n",
        "    prec=\"fp16\"\n",
        "    precision=prec\n",
        "\n",
        "    GC=\"--gradient_checkpointing\"\n",
        "    s = getoutput('nvidia-smi')\n",
        "    if 'A100' in s:\n",
        "        GC=\"\"\n",
        "        \n",
        "    External_Captions = False\n",
        "\n",
        "    resuming=\"\"\n",
        "\n",
        "    stp=0\n",
        "    Start_saving_from_the_step=0\n",
        "    stpsv=Start_saving_from_the_step\n",
        "\n",
        "    Disconnect_after_training=False\n",
        "\n",
        "\n",
        "    # 텍스트 인코더 트레이닝\n",
        "    if Enable_text_encoder_training :\n",
        "        print('Training the text encoder...')\n",
        "        if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
        "            %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
        "        dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "\n",
        "    # 유넷 트레이닝\n",
        "    if UNet_Training_Steps!=0:\n",
        "        train_only_unet(stptxt, stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n",
        "\n",
        "    # feature_extractor, safety_checker, model_index.json 커스텀 모델 파일에 추가\n",
        "    try:\n",
        "        shutil.copytree(\"/content/stable-diffusion-v1-5/feature_extractor\", OUTPUT_DIR + \"/feature_extractor\")\n",
        "    except:\n",
        "        print(f\"File exists: '/content/models/{Session_Name}/feature_extractor'\")\n",
        "    try:    \n",
        "        shutil.copytree(\"/content/stable-diffusion-v1-5/safety_checker\", OUTPUT_DIR + \"/safety_checker\")\n",
        "    except:\n",
        "        print(f\"File exists: '/content/models/{Session_Name}/safety_checker'\")\n",
        "\n",
        "    shutil.copyfile('/content/stable-diffusion-v1-5/model_index.json', OUTPUT_DIR + \"/model_index.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Huggingface_Token = \"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\"\n",
        "token=Huggingface_Token\n",
        "\n",
        "# Session Name\n",
        "print('Input the Session Name:') \n",
        "Session_Name=input('')\n",
        "\n",
        "sd_custom_function(token, Session_Name, 800, 1e-5, 350, 1e-6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "0t7HPmQOqn6P",
        "outputId": "4687ca8c-f053-4c7c-8f38-08d2b0e4299f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the UNet...\n",
            "\u001b[34m'########:'########:::::'###::::'####:'##::: ##:'####:'##::: ##::'######:::\n",
            "... ##..:: ##.... ##:::'## ##:::. ##:: ###:: ##:. ##:: ###:: ##:'##... ##::\n",
            "::: ##:::: ##:::: ##::'##:. ##::: ##:: ####: ##:: ##:: ####: ##: ##:::..:::\n",
            "::: ##:::: ########::'##:::. ##:: ##:: ## ## ##:: ##:: ## ## ##: ##::'####:\n",
            "::: ##:::: ##.. ##::: #########:: ##:: ##. ####:: ##:: ##. ####: ##::: ##::\n",
            "::: ##:::: ##::. ##:: ##.... ##:: ##:: ##:. ###:: ##:: ##:. ###: ##::: ##::\n",
            "::: ##:::: ##:::. ##: ##:::: ##:'####: ##::. ##:'####: ##::. ##:. ######:::\n",
            ":::..:::::..:::::..::..:::::..::....::..::::..::....::..::::..:::......::::\n",
            "\u001b[0m\n",
            "2023-01-26 01:56:48.795933: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "Progress:|█████████████████████████|100% 800/800 [03:56<00:00,  3.38it/s, loss=0.194, lr=1e-7]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}