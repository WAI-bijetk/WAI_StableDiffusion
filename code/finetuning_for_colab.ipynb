{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-PeTqetTOAw"
      },
      "source": [
        "## Fine-Tuning of Stable Diffusion for Colab\n",
        "basecode : [How to Use DreamBooth to Fine-Tune Stable Diffusion by EdXD](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-hPB4tRUOjA",
        "outputId": "8a0e1215-0340-46d6-fefe-bade45eaa9b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Installing dependencies...\n",
            "Done, proceed\n"
          ]
        }
      ],
      "source": [
        "## Environment\n",
        "\n",
        "### Google Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "import time\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "### Installing dependencies\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/\n",
        "    !pip install -q --no-deps accelerate==0.12.0\n",
        "    !wget -q -i \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/dbdeps.txt\"\n",
        "    for i in range(1,8):\n",
        "        !mv \"deps.{i}\" \"deps.7z.00{i}\"\n",
        "    !7z x -y -o/ deps.7z.001\n",
        "    !rm *.00* *.txt\n",
        "    !git clone --depth 1 --branch updt https://github.com/TheLastBen/diffusers\n",
        "    s = getoutput('nvidia-smi')\n",
        "    if \"A100\" in s:\n",
        "        !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/A100\n",
        "        !rm -r /usr/local/lib/python3.8/dist-packages/xformers\n",
        "        !7z x -y -o/usr/local/lib/python3.8/dist-packages/ /content/A100\n",
        "        !rm /content/A100\n",
        "print('Done, proceed')\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "import shutil\n",
        "from os import listdir\n",
        "from os.path import isfile\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "import random\n",
        "import shutil\n",
        "from google.colab import runtime\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XlZ-qmFrTNAa"
      },
      "outputs": [],
      "source": [
        "## Def Dunction\n",
        "\n",
        "### Training Text Encoder\n",
        "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $trnonltxt \\\n",
        "    --image_captions_filename \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$txlr \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "# Training UNet\n",
        "def train_only_unet(stptxt, stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
        "\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Style \\\n",
        "    $extrnlcptn \\\n",
        "    --stop_text_encoder_training=$stptxt \\\n",
        "    --image_captions_filename \\\n",
        "    --train_only_unet \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$untlr \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "WUMs0jaHQ1rt",
        "outputId": "337fed2e-4d37-42d0-c3ed-f3b40f5f5d7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  |███████████████| 21/21 Uploaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "upload image Done, proceed to the next cell\n",
            "<class 'int'>\n",
            "Training the text encoder...\n",
            "\u001b[34m'########:'########:::::'###::::'####:'##::: ##:'####:'##::: ##::'######:::\n",
            "... ##..:: ##.... ##:::'## ##:::. ##:: ###:: ##:. ##:: ###:: ##:'##... ##::\n",
            "::: ##:::: ##:::: ##::'##:. ##::: ##:: ####: ##:: ##:: ####: ##: ##:::..:::\n",
            "::: ##:::: ########::'##:::. ##:: ##:: ## ## ##:: ##:: ## ## ##: ##::'####:\n",
            "::: ##:::: ##.. ##::: #########:: ##:: ##. ####:: ##:: ##. ####: ##::: ##::\n",
            "::: ##:::: ##::. ##:: ##.... ##:: ##:: ##:. ###:: ##:: ##:. ###: ##::: ##::\n",
            "::: ##:::: ##:::. ##: ##:::: ##:'####: ##::. ##:'####: ##::. ##:. ######:::\n",
            ":::..:::::..:::::..::..:::::..::....::..::::..::....::..::::..:::......::::\n",
            "\u001b[0m\n",
            "Progress:|█████████████████████████|100% 350/350 [05:15<00:00,  1.11it/s, loss=0.00669, lr=1e-7]\n",
            "Training the UNet...\n",
            "\u001b[34m'########:'########:::::'###::::'####:'##::: ##:'####:'##::: ##::'######:::\n",
            "... ##..:: ##.... ##:::'## ##:::. ##:: ###:: ##:. ##:: ###:: ##:'##... ##::\n",
            "::: ##:::: ##:::: ##::'##:. ##::: ##:: ####: ##:: ##:: ####: ##: ##:::..:::\n",
            "::: ##:::: ########::'##:::. ##:: ##:: ## ## ##:: ##:: ## ## ##: ##::'####:\n",
            "::: ##:::: ##.. ##::: #########:: ##:: ##. ####:: ##:: ##. ####: ##::: ##::\n",
            "::: ##:::: ##::. ##:: ##.... ##:: ##:: ##:. ###:: ##:: ##:. ###: ##::: ##::\n",
            "::: ##:::: ##:::. ##: ##:::: ##:'####: ##::. ##:'####: ##::. ##:. ######:::\n",
            ":::..:::::..:::::..::..:::::..::....::..::::..::....::..::::..:::......::::\n",
            "\u001b[0m\n",
            "Progress:|█████████████████████████|100% 800/800 [11:15<00:00,  1.18it/s, loss=0.0358, lr=1e-7]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/0131_new_3/model_index.json'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Main\n",
        "\n",
        "# token\n",
        "print('Input the Huggingface Token: ')\n",
        "Huggingface_Token = input('')\n",
        "token=Huggingface_Token\n",
        "\n",
        "# Session Name\n",
        "print('Input the Session Name:') \n",
        "Session_Name=input('')\n",
        "\n",
        "# Directory Declare\n",
        "WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n",
        "INSTANCE_NAME=Session_Name\n",
        "OUTPUT_DIR=\"/content/models/\"+ Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+ Session_Name\n",
        "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
        "CONCEPT_DIR=SESSION_DIR+'/concept_images'\n",
        "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
        "MDLPTH=str(SESSION_DIR+\"/\"+ Session_Name+'.ckpt')\n",
        "PT=\"\"\n",
        "\n",
        "# Variable Declare\n",
        "UNet_Training_Steps = 800\n",
        "UNet_Learning_Rate = 1e-5\n",
        "Text_Encoder_Training_Steps = 350\n",
        "Text_Encoder_Learning_Rate = 1e-6\n",
        "\n",
        "# Model Download\n",
        "if not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    #######################################################################################################################\n",
        "    ######## downloadmodel(token) ##############################\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "        !rm -r /content/stable-diffusion-v1-5\n",
        "    clear_output()\n",
        "\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    !mkdir /content/stable-diffusion-v1-5\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nfeature_extractor\\nsafety_checker\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "        !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "        !rm -r /content/stable-diffusion-v1-5/.git\n",
        "        %cd /content/stable-diffusion-v1-5\n",
        "        !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "        !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "        !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json  \n",
        "        %cd /content/    \n",
        "        clear_output()\n",
        "        print('DONE !')\n",
        "    else:\n",
        "        while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "            print('Make sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "            time.sleep(5)\n",
        "    #######################################################################################################################\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "else:\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "    print(\"The v1.5 model already exists, using this model.\")  \n",
        "    \n",
        "# create/load session\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content\n",
        "\n",
        "###########################################################################################################################  \n",
        "# sd_custom_create_session(MODEL_NAME, SESSION_DIR, MDLPTH, OUTPUT_DIR)    \n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
        "    print('Loading session with no previous model, using the original model or the custom downloaded model')\n",
        "    if MODEL_NAME==\"\":\n",
        "        print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "    else:\n",
        "        print('Session Loaded, proceed to uploading instance images')\n",
        "\n",
        "elif os.path.exists(MDLPTH):\n",
        "    print('Session found, loading the trained model ...')\n",
        "    !wget -q -O refmdlz https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/refmdlz\n",
        "    !unzip -o -q refmdlz\n",
        "    !rm -f refmdlz\n",
        "    !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv1.py\n",
        "    clear_output()\n",
        "    print('Session found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v1\n",
        "    !rm -r /content/refmdl\n",
        "    !rm /content/convertodiff.py  \n",
        "    if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "        resume=True    \n",
        "        clear_output()\n",
        "        print('Session loaded.')\n",
        "    else:     \n",
        "        if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "            print('Conversion error, if the error persists, remove the CKPT file from the current session folder')\n",
        "\n",
        "elif not os.path.exists(str(SESSION_DIR)):\n",
        "    %mkdir -p \"$INSTANCE_DIR\"\n",
        "    print('Creating session...')\n",
        "    if MODEL_NAME==\"\":\n",
        "        print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "    else:\n",
        "        print('Session created, proceed to uploading instance images')\n",
        "############################################################################################################\n",
        "\n",
        "# Instant_image\n",
        "\n",
        "############################################################################################################\n",
        "# sd_custom_prepare_image_upload(CAPTIONS_DIR, INSTANCE_DIR)\n",
        "if os.path.exists(CAPTIONS_DIR+\"off\"):\n",
        "    !mv $CAPTIONS_DIR\"off\" $CAPTIONS_DIR\n",
        "    time.sleep(3)\n",
        "\n",
        "if os.path.exists(str(INSTANCE_DIR)):\n",
        "    !rm -r \"$INSTANCE_DIR\"\n",
        "if os.path.exists(str(CAPTIONS_DIR)):\n",
        "    !rm -r \"$CAPTIONS_DIR\"\n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "    %mkdir -p \"$INSTANCE_DIR\"\n",
        "if not os.path.exists(str(CAPTIONS_DIR)):\n",
        "    %mkdir -p \"$CAPTIONS_DIR\"\n",
        "\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "    %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "############################################################################################################\n",
        "\n",
        "up=\"\"  \n",
        "uploaded = files.upload()\n",
        "\n",
        "############################################################################################################\n",
        "# sd_custom_uploaded_image(uploaded, CAPTIONS_DIR, INSTANCE_DIR)\n",
        "for filename in uploaded.keys():\n",
        "    if filename.split(\".\")[-1]==\"txt\":\n",
        "        shutil.move(filename, CAPTIONS_DIR)\n",
        "    up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n",
        "\n",
        "for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "    shutil.move(filename, INSTANCE_DIR)\n",
        "    clear_output()\n",
        "print('upload image Done, proceed to the next cell')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    %cd \"$INSTANCE_DIR\"\n",
        "    !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "    %cd \"$CAPTIONS_DIR\"\n",
        "    !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "    \n",
        "    %cd $SESSION_DIR\n",
        "    !rm instance_images.zip captions.zip\n",
        "    !zip -r instance_images instance_images\n",
        "    !zip -r captions captions\n",
        "    %cd /content\n",
        "############################################################################################################\n",
        "    \n",
        "# training\n",
        "\n",
        "\n",
        "Resume_Training = False\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "# UNet\n",
        "UNet_Training_Steps=UNet_Training_Steps \n",
        "UNet_Learning_Rate = UNet_Learning_Rate\n",
        "untlr=UNet_Learning_Rate\n",
        "\n",
        "# Text_Encoder\n",
        "Enable_text_encoder_training= True\n",
        "Text_Encoder_Training_Steps=Text_Encoder_Training_Steps\n",
        "Text_Encoder_Learning_Rate = Text_Encoder_Learning_Rate #param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n",
        "stptxt=Text_Encoder_Training_Steps\n",
        "txlr=Text_Encoder_Learning_Rate\n",
        "\n",
        "Enable_Text_Encoder_Concept_Training= False\n",
        "Text_Encoder_Concept_Training_Steps=0\n",
        "\n",
        "# Seed\n",
        "Seed=\"\"\n",
        "if Seed =='' or Seed=='0':\n",
        "    Seed=random.randint(1, 999999)\n",
        "else:\n",
        "    Seed=int(Seed)\n",
        "print(type(Seed))\n",
        "trnonltxt=\"\"\n",
        "\n",
        "extrnlcptn=\"\"\n",
        "Style=\"\"\n",
        "\n",
        "Resolution = \"512\" #param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "Res=int(Resolution)\n",
        "\n",
        "fp16 = True\n",
        "prec=\"fp16\"\n",
        "precision=prec\n",
        "\n",
        "GC=\"--gradient_checkpointing\"\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "    GC=\"\"\n",
        "    \n",
        "External_Captions = False\n",
        "\n",
        "resuming=\"\"\n",
        "\n",
        "stp=0\n",
        "Start_saving_from_the_step=0\n",
        "stpsv=Start_saving_from_the_step\n",
        "\n",
        "Disconnect_after_training=False\n",
        "\n",
        "\n",
        "# Text Encoder Training\n",
        "if Enable_text_encoder_training :\n",
        "    print('Training the text encoder...')\n",
        "    if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
        "        %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
        "    dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, stptxt)\n",
        "\n",
        "# UNet Training\n",
        "if UNet_Training_Steps!=0:\n",
        "    print('Training the UNet...')\n",
        "    train_only_unet(stptxt, stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, UNet_Training_Steps)\n",
        "\n",
        "# Copy feature_extractor, safety_checker, model_index.json\n",
        "try:\n",
        "    shutil.copytree(\"/content/stable-diffusion-v1-5/feature_extractor\", OUTPUT_DIR + \"/feature_extractor\")\n",
        "except:\n",
        "    print(f\"File exists: '/content/models/{Session_Name}/feature_extractor'\")\n",
        "try:    \n",
        "    shutil.copytree(\"/content/stable-diffusion-v1-5/safety_checker\", OUTPUT_DIR + \"/safety_checker\")\n",
        "except:\n",
        "    print(f\"File exists: '/content/models/{Session_Name}/safety_checker'\")\n",
        "\n",
        "shutil.copyfile('/content/stable-diffusion-v1-5/model_index.json', OUTPUT_DIR + \"/model_index.json\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
